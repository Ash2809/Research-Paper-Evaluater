{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "import pandas as pd\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "from langchain.schema import Document\n",
    "from langgraph.graph import START, StateGraph, END\n",
    "from typing import Literal, List\n",
    "from typing_extensions import TypedDict\n",
    "from dotenv import load_dotenv\n",
    "from PIL import Image\n",
    "import json\n",
    "import os\n",
    "import pprint\n",
    "from langchain_core.prompts.chat import SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "GOOGLE_API_KEY = \"AIzaSyAEqCEpjV4_6nZFKGQv8cxiyffiUNdDjGE\"\n",
    "llm = ChatGoogleGenerativeAI(api_key = GOOGLE_API_KEY, model = \"gemini-1.5-flash\",temperature = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    result : str  \n",
    "    doc : str  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def authenticate_drive():\n",
    "    gauth = GoogleAuth()\n",
    "    gauth.LoadClientConfigFile(r\"C:\\Users\\aashutosh kumar\\Downloads\\Client_secrets.json\")  # Update path\n",
    "    gauth.LocalWebserverAuth()  \n",
    "    return gauth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauth = GoogleAuth()\n",
    "gauth.LoadClientConfigFile(r\"C:\\Users\\aashutosh kumar\\Downloads\\Client_secrets.json\")  # Update path\n",
    "gauth.LocalWebserverAuth()  # Authenticate with a browser "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_decider(doc):\n",
    "    print(doc[:100]) \n",
    "    \n",
    "    class decide(BaseModel):\n",
    "        Binary_Score: str = Field(..., description=\"Is this Report Publishable?, respond with Yes or No.\")\n",
    "    \n",
    "    structured_llm = llm.with_structured_output(decide)\n",
    "    \n",
    "    system = \"\"\"\n",
    "    You are an AI system tasked with determining whether a given document is a publishable research paper. A publishable research paper must meet the following criteria:\n",
    "\n",
    "    1. Structure:\n",
    "    - The document includes a title, abstract, introduction, methodology, results, discussion, and references.\n",
    "    \n",
    "    2. **Content**:\n",
    "    - The document presents original research, analysis, or findings.\n",
    "    - It has a clear research question, hypothesis, or objective.\n",
    "    - The methodology is well-detailed and appropriate for the research question.\n",
    "    - Results are presented with supporting data, graphs, or tables.\n",
    "\n",
    "    3. **Language and Formatting**:\n",
    "    - The writing is clear, concise, and follows academic standards.\n",
    "    - Proper citations and references are included in a recognized citation style.\n",
    "\n",
    "    4. **Credibility**:\n",
    "    - Sources cited in the references are credible and relevant to the topic.\n",
    "    - The claims made are supported by sufficient evidence.\n",
    "\n",
    "    Your task is to analyze the provided document and respond with \"Yes\" if it meets these criteria for publication or \"No\" if it does not.\n",
    "\n",
    "    Document: {doc}\n",
    "    \"\"\"  \n",
    "    \n",
    "    binary_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\"human\", f\"paper: {doc}\")\n",
    "        ]\n",
    "    )\n",
    "        # Check if structured_llm is correctly set up\n",
    "    print(\"Calling LLM with the prompt...\")\n",
    "    llm\n",
    "    \n",
    "    grader_chain = binary_prompt | structured_llm\n",
    "    \n",
    "    try:\n",
    "        llm_response = grader_chain.invoke({\"doc\": doc})\n",
    "        print(\"LLM Response received successfully.\")\n",
    "        \n",
    "        prediction_output = llm_response.Binary_Score\n",
    "        print(prediction_output)\n",
    "        return \n",
    "    except Exception as e:\n",
    "        print(f\"Error during LLM invocation: {e}\")\n",
    "        return {\"prediction\": None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "import os\n",
    "\n",
    "def authenticate_drive():\n",
    "    \"\"\"\n",
    "    Authenticates the Google Drive account and returns a GoogleDrive object.\n",
    "    \"\"\"\n",
    "    gauth = GoogleAuth()\n",
    "    gauth.LoadClientConfigFile(r\"C:\\Users\\aashutosh kumar\\Downloads\\Client_secrets.json\")  \n",
    "    gauth.LocalWebserverAuth()  \n",
    "    return GoogleDrive(gauth)  \n",
    "\n",
    "def fetch_pdfs_from_drive(drive, folder_id, download_dir):\n",
    "    \"\"\"\n",
    "    Fetches all PDF files from the specified Google Drive folder and downloads them.\n",
    "    \"\"\"\n",
    "    query = f\"'{folder_id}' in parents and mimeType='application/pdf'\"\n",
    "    file_list = drive.ListFile({'q': query}).GetList()\n",
    "\n",
    "    print(f\"Found {len(file_list)} PDF files in the folder.\")\n",
    "    for file in file_list:\n",
    "        print(f\"Downloading {file['title']}...\")\n",
    "        file.GetContentFile(os.path.join(download_dir, file['title']))\n",
    "    print(\"All files downloaded successfully!\")\n",
    "\n",
    "def process_papers_from_drive(download_dir, output_csv):\n",
    "\n",
    "    pdf_files = [os.path.join(download_dir, f) for f in os.listdir(download_dir) if f.endswith('.pdf')]\n",
    "\n",
    "    results = []\n",
    "    for i, file_path in enumerate(pdf_files):\n",
    "        print(f\"Processing file {i + 1}/{len(pdf_files)}: {file_path}\")\n",
    "\n",
    "        loader = PyPDFLoader(file_path)\n",
    "        documents = loader.load()\n",
    "\n",
    "        doc_text = \" \".join([doc.page_content for doc in documents])\n",
    "        sanitized_text = doc_text.replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    "\n",
    "        result = report_decider(sanitized_text)\n",
    "        print(result)\n",
    "        results.append({\"File\": os.path.basename(file_path), \"Result\": result})\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Results saved to {output_csv}\")\n",
    "\n",
    "\n",
    "folder_id = \"1Y2Y0EsMalo26KcJiPYcAXh6UzgMNjh4u\"  \n",
    "download_dir = r\"C:\\Projects\\Research-Paper-Evaluater\\data\"  \n",
    "output_csv = \"results.csv\"  \n",
    "\n",
    "os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "# drive = authenticate_drive()\n",
    "# fetch_pdfs_from_drive(drive, folder_id, download_dir)\n",
    "\n",
    "# Process files and save results\n",
    "process_papers_from_drive(download_dir, output_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_conference(doc):\n",
    "    \"\"\"\n",
    "    Classifies a document into a suitable conference and provides a rationale.\n",
    "    Args:\n",
    "        doc (str): The content of the document to classify.\n",
    "    \"\"\"\n",
    "    system_message = \"\"\"\n",
    "    You are an AI system tasked with determining whether a given document is publishable in one \n",
    "    of the following conferences: CVPR, NeurIPS, EMNLP, TMLR, and KDD.\n",
    "    Each classification must be accompanied by a well-reasoned rationale of up to 100 words, explaining how the paperâ€™s content, methodology,\n",
    "    and findings correspond to the themes, focus areas, and quality standards of the\n",
    "    chosen conference. This rationale will ensure that the paper is not only a good fit\n",
    "    for the conference but also adheres to the academic criteria expected by these\n",
    "    prestigious venues.\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [\n",
    "        SystemMessage(content=system_message),\n",
    "        HumanMessage(content=f\"Paper: {doc}\")\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response = llm.invoke(messages)\n",
    "        print(response.content)\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This paper is best suited for **KDD** (Knowledge Discovery and Data Mining).\n",
      "\n",
      "**Rationale:** The paper focuses on developing a novel deep learning model (MDCSA) for indoor localization using multimodal data (RSSI and accelerometer) from wearable sensors.  The application is in monitoring Parkinson's disease progression by analyzing in-home gait patterns to predict medication states. This aligns perfectly with KDD's interest in data mining techniques, machine learning for real-world applications, and the discovery of knowledge from complex datasets. The evaluation methodology, using various cross-validation strategies, is rigorous and relevant to the KDD community's focus on robust and generalizable algorithms.  The use of a real-world dataset further strengthens its suitability for KDD.  While elements touch upon aspects of other conferences (e.g., the methodology in NeurIPS), the core contribution and application are most strongly aligned with KDD's scope.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loader = PyPDFLoader(r\"C:\\Users\\aashutosh kumar\\Downloads\\R010.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "doc_text = \" \".join([doc.page_content for doc in documents])\n",
    "sanitized_text = doc_text.replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    "classify_conference(sanitized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
