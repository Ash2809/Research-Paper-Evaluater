{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\a\\envs\\env2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\a\\envs\\env2\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3577: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "import pandas as pd\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.schema import Document\n",
    "from langgraph.graph import START, StateGraph, END\n",
    "from typing import Literal, List\n",
    "from typing_extensions import TypedDict\n",
    "from dotenv import load_dotenv\n",
    "from PIL import Image\n",
    "import json\n",
    "import os\n",
    "import pprint\n",
    "from langchain_core.prompts.chat import SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "GOOGLE_API_KEY = \"AIzaSyAEqCEpjV4_6nZFKGQv8cxiyffiUNdDjGE\"\n",
    "llm = ChatGoogleGenerativeAI(api_key = GOOGLE_API_KEY, model = \"gemini-1.5-flash\",temperature = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    result : str  \n",
    "    doc : str  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def authenticate_drive():\n",
    "    gauth = GoogleAuth()\n",
    "    gauth.LoadClientConfigFile(r\"C:\\Users\\aashutosh kumar\\Downloads\\Client_secrets.json\")  # Update path\n",
    "    gauth.LocalWebserverAuth()  \n",
    "    return gauth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?client_id=745687906844-la0jv2qvbkf9ifscdhivus6p0mj9ado8.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&access_type=offline&response_type=code\n",
      "\n",
      "Authentication successful.\n"
     ]
    }
   ],
   "source": [
    "gauth = GoogleAuth()\n",
    "gauth.LoadClientConfigFile(r\"C:\\Users\\aashutosh kumar\\Downloads\\Client_secrets.json\")  # Update path\n",
    "gauth.LocalWebserverAuth()  # Authenticate with a browser "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_decider(doc):\n",
    "    print(doc[:100]) \n",
    "    \n",
    "    class decide(BaseModel):\n",
    "        Binary_Score: str = Field(..., description=\"Is this Report Publishable?, respond with Yes or No.\")\n",
    "    \n",
    "    structured_llm = llm.with_structured_output(decide)\n",
    "    \n",
    "    system = \"\"\"\n",
    "    You are an AI system tasked with determining whether a given document is a publishable research paper. A publishable research paper must meet the following criteria:\n",
    "\n",
    "    1. Structure:\n",
    "    - The document includes a title, abstract, introduction, methodology, results, discussion, and references.\n",
    "    \n",
    "    2. **Content**:\n",
    "    - The document presents original research, analysis, or findings.\n",
    "    - It has a clear research question, hypothesis, or objective.\n",
    "    - The methodology is well-detailed and appropriate for the research question.\n",
    "    - Results are presented with supporting data, graphs, or tables.\n",
    "\n",
    "    3. **Language and Formatting**:\n",
    "    - The writing is clear, concise, and follows academic standards.\n",
    "    - Proper citations and references are included in a recognized citation style.\n",
    "\n",
    "    4. **Credibility**:\n",
    "    - Sources cited in the references are credible and relevant to the topic.\n",
    "    - The claims made are supported by sufficient evidence.\n",
    "\n",
    "    Your task is to analyze the provided document and respond with \"Yes\" if it meets these criteria for publication or \"No\" if it does not.\n",
    "\n",
    "    Document: {doc}\n",
    "    \"\"\"  \n",
    "    \n",
    "    binary_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\"human\", f\"paper: {doc}\")\n",
    "        ]\n",
    "    )\n",
    "        # Check if structured_llm is correctly set up\n",
    "    print(\"Calling LLM with the prompt...\")\n",
    "    llm\n",
    "    \n",
    "    grader_chain = binary_prompt | structured_llm\n",
    "    \n",
    "    try:\n",
    "        llm_response = grader_chain.invoke({\"doc\": doc})\n",
    "        print(\"LLM Response received successfully.\")\n",
    "        \n",
    "        prediction_output = llm_response.Binary_Score\n",
    "        print(prediction_output)\n",
    "        return \n",
    "    except Exception as e:\n",
    "        print(f\"Error during LLM invocation: {e}\")\n",
    "        return {\"prediction\": None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 1/5: C:\\Projects\\Research-Paper-Evaluater\\data\\P001.pdf\n",
      "Leveraging\n",
      "Calling LLM with the prompt...\n",
      "LLM Response received successfully.\n",
      "Yes\n",
      "Yes\n",
      "Processing file 2/5: C:\\Projects\\Research-Paper-Evaluater\\data\\P002.pdf\n",
      "Virus Prop\n",
      "Calling LLM with the prompt...\n",
      "LLM Response received successfully.\n",
      "No\n",
      "No\n",
      "Processing file 3/5: C:\\Projects\\Research-Paper-Evaluater\\data\\P003.pdf\n",
      "Explainabl\n",
      "Calling LLM with the prompt...\n",
      "LLM Response received successfully.\n",
      "No\n",
      "No\n",
      "Processing file 4/5: C:\\Projects\\Research-Paper-Evaluater\\data\\P004.pdf\n",
      "Graph Neur\n",
      "Calling LLM with the prompt...\n",
      "LLM Response received successfully.\n",
      "Yes\n",
      "Yes\n",
      "Processing file 5/5: C:\\Projects\\Research-Paper-Evaluater\\data\\P005.pdf\n",
      "Collaborat\n",
      "Calling LLM with the prompt...\n",
      "LLM Response received successfully.\n",
      "Yes\n",
      "Yes\n",
      "Results saved to results.csv\n"
     ]
    }
   ],
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "import os\n",
    "\n",
    "def authenticate_drive():\n",
    "    \"\"\"\n",
    "    Authenticates the Google Drive account and returns a GoogleDrive object.\n",
    "    \"\"\"\n",
    "    gauth = GoogleAuth()\n",
    "    gauth.LoadClientConfigFile(r\"C:\\Users\\aashutosh kumar\\Downloads\\Client_secrets.json\")  \n",
    "    gauth.LocalWebserverAuth()  \n",
    "    return GoogleDrive(gauth)  \n",
    "\n",
    "def fetch_pdfs_from_drive(drive, folder_id, download_dir):\n",
    "    \"\"\"\n",
    "    Fetches all PDF files from the specified Google Drive folder and downloads them.\n",
    "    \"\"\"\n",
    "    query = f\"'{folder_id}' in parents and mimeType='application/pdf'\"\n",
    "    file_list = drive.ListFile({'q': query}).GetList()\n",
    "\n",
    "    print(f\"Found {len(file_list)} PDF files in the folder.\")\n",
    "    for file in file_list:\n",
    "        print(f\"Downloading {file['title']}...\")\n",
    "        file.GetContentFile(os.path.join(download_dir, file['title']))\n",
    "    print(\"All files downloaded successfully!\")\n",
    "\n",
    "def process_papers_from_drive(download_dir, output_csv):\n",
    "\n",
    "    pdf_files = [os.path.join(download_dir, f) for f in os.listdir(download_dir) if f.endswith('.pdf')]\n",
    "\n",
    "    results = []\n",
    "    for i, file_path in enumerate(pdf_files):\n",
    "        print(f\"Processing file {i + 1}/{len(pdf_files)}: {file_path}\")\n",
    "\n",
    "        loader = PyPDFLoader(file_path)\n",
    "        documents = loader.load()\n",
    "\n",
    "        doc_text = \" \".join([doc.page_content for doc in documents])\n",
    "        sanitized_text = doc_text.replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    "\n",
    "        result = report_decider(sanitized_text)\n",
    "        print(result)\n",
    "        results.append({\"File\": os.path.basename(file_path), \"Result\": result})\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Results saved to {output_csv}\")\n",
    "\n",
    "\n",
    "folder_id = \"1Y2Y0EsMalo26KcJiPYcAXh6UzgMNjh4u\"  \n",
    "download_dir = r\"C:\\Projects\\Research-Paper-Evaluater\\data\"  \n",
    "output_csv = \"results.csv\"  \n",
    "\n",
    "os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "# drive = authenticate_drive()\n",
    "# fetch_pdfs_from_drive(drive, folder_id, download_dir)\n",
    "\n",
    "# Process files and save results\n",
    "process_papers_from_drive(download_dir, output_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
