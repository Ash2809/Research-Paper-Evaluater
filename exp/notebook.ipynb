{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This is not the real Pathway package.\n",
      "Visit https://pathway.com/developers/ to get Pathway.\n",
      "Already tried that? Visit https://pathway.com/troubleshooting/ to get help.\n",
      "Note: your platform is Windows-10-10.0.22631-SP0, your Python is CPython 3.10.16.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, f1_score\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Step 1: Mount Google Drive\u001b[39;00m\n\u001b[0;32m     11\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathway as pw\n",
    "import pdfplumber\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from google.colab import drive\n",
    "\n",
    "# Step 1: Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "data_dir = \"/content/drive/My Drive/references\"  # Path to Google Drive dataset directory\n",
    "publishable_dir = os.path.join(data_dir, \"publishable\")\n",
    "non_publishable_dir = os.path.join(data_dir, \"non-publishable\")\n",
    "\n",
    "# Step 2: Define File Parsing Logic\n",
    "def parse_content(file_path):\n",
    "    if file_path.endswith('.pdf'):\n",
    "        with pdfplumber.open(file_path) as pdf:\n",
    "            return \"\\n\".join([page.extract_text() for page in pdf.pages])\n",
    "    return \"\"  # Handle unsupported formats\n",
    "\n",
    "# Step 3: Load Data into Pathway Table\n",
    "# Load publishable papers\n",
    "publishable_files = [(file, os.path.join(publishable_dir, file), 1) for file in os.listdir(publishable_dir) if file.endswith('.pdf')]\n",
    "\n",
    "# Load non-publishable papers\n",
    "non_publishable_files = [(file, os.path.join(non_publishable_dir, file), 0) for file in os.listdir(non_publishable_dir) if file.endswith('.pdf')]\n",
    "\n",
    "# Combine data\n",
    "file_records = publishable_files + non_publishable_files\n",
    "\n",
    "file_table = pw.Table.from_records(\n",
    "    file_records,\n",
    "    schema=[\"file_name\", \"file_path\", \"label\"]\n",
    ")\n",
    "\n",
    "# Parse files and add content to the table\n",
    "parsed_table = file_table.map_rows(\n",
    "    lambda row: {\n",
    "        \"file_name\": row[\"file_name\"],\n",
    "        \"content\": parse_content(row[\"file_path\"]),\n",
    "        \"label\": row[\"label\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Step 4: Train a Classification Model\n",
    "# Collect labeled data for training\n",
    "texts = [row[\"content\"] for row in parsed_table.collect_rows()]\n",
    "labels = [row[\"label\"] for row in parsed_table.collect_rows()]\n",
    "\n",
    "# Convert texts to TF-IDF features\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "X = vectorizer.fit_transform(texts)\n",
    "y = labels\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Naive Bayes classifier\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "predictions = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# Step 5: Apply Model to Unlabeled Data\n",
    "# Predict labels for all parsed data (useful for validation)\n",
    "predicted_labels = model.predict(vectorizer.transform(texts))\n",
    "\n",
    "# Add predictions back to the table\n",
    "predicted_table = parsed_table.map_rows(\n",
    "    lambda row, pred=predicted_labels: {\n",
    "        \"file_name\": row[\"file_name\"],\n",
    "        \"content\": row[\"content\"],\n",
    "        \"true_label\": row[\"label\"],\n",
    "        \"predicted_label\": pred.pop(0),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Step 6: Save Results\n",
    "output_table = predicted_table.map_rows(\n",
    "    lambda row: {\n",
    "        \"Paper ID\": row[\"file_name\"],\n",
    "        \"True Label\": row[\"true_label\"],\n",
    "        \"Predicted Label\": row[\"predicted_label\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "pw.io.write_csv(output_table, \"results.csv\")\n",
    "\n",
    "print(\"Pipeline executed successfully. Results saved to results.csv.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
